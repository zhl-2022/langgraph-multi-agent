# verify_qwen_models.py
from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification
import torch
from config import Config

def verify_qwen_models():
    """éªŒè¯Qwenæ¨¡å‹é…ç½®"""
    config = Config()
    
    print("ğŸ” éªŒè¯Qwenæ¨¡å‹é…ç½®")
    print("=" * 50)
    
    try:
        # éªŒè¯Embeddingæ¨¡å‹
        print("ğŸ“ éªŒè¯Embeddingæ¨¡å‹...")
        embedding_tokenizer = AutoTokenizer.from_pretrained(
            config.EMBEDDING_MODEL_PATH,
            trust_remote_code=True
        )
        embedding_model = AutoModel.from_pretrained(
            config.EMBEDDING_MODEL_PATH,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True
        )
        
        # æµ‹è¯•Embedding
        texts = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"]
        embeddings = embedding_model.embed_documents(texts)
        print(f"âœ… Embeddingæ¨¡å‹: {config.EMBEDDING_MODEL_PATH}")
        print(f"ğŸ“ Embeddingç»´åº¦: {embeddings.shape[1]}")
        print(f"ğŸ“ æ ·æœ¬æ•°é‡: {embeddings.shape[0]}")
        
        # éªŒè¯Rerankeræ¨¡å‹
        print("\nğŸ” éªŒè¯Rerankeræ¨¡å‹...")
        reranker_tokenizer = AutoTokenizer.from_pretrained(
            config.RERANKER_MODEL_PATH,
            trust_remote_code=True
        )
        reranker_model = AutoModelForSequenceClassification.from_pretrained(
            config.RERANKER_MODEL_PATH,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True
        )
        
        print(f"âœ… Rerankeræ¨¡å‹: {config.RERANKER_MODEL_PATH}")
        print("ğŸ¯ Rerankeræ¨¡å‹åŠ è½½æˆåŠŸ")
        
        return embeddings.shape[1]
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    verify_qwen_models()