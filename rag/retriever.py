# rag/retriever.py
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from typing import List, Dict, Optional
from config import Config
import os
import logging

logger = logging.getLogger(__name__)

class QwenReranker:
    """Qwen3-Rerankeræ¨¡å‹å°è£… - ä¿®å¤ç‰ˆæœ¬"""
    def __init__(self, model_path: str):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½Qwen3-Rerankeræ¨¡å‹"""
        try:
            print(f"ğŸ”„ åŠ è½½Qwen3-Rerankeræ¨¡å‹ä»: {self.model_path}")
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
            
            # å…ˆåŠ è½½tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_path,
                trust_remote_code=True
            )
            
            # å…³é”®ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®padding token
            if self.tokenizer.pad_token is None:
                if self.tokenizer.eos_token is not None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                    print(f"âœ… ä½¿ç”¨eos_tokenä½œä¸ºpad_token: {self.tokenizer.pad_token}")
                elif self.tokenizer.unk_token is not None:
                    self.tokenizer.pad_token = self.tokenizer.unk_token
                    print(f"âœ… ä½¿ç”¨unk_tokenä½œä¸ºpad_token: {self.tokenizer.pad_token}")
                else:
                    # å¦‚æœéƒ½æ²¡æœ‰ï¼Œæ·»åŠ ä¸€ä¸ªç‰¹æ®Šçš„pad_token
                    self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})
                    print("âœ… æ·»åŠ äº†æ–°çš„pad_token: [PAD]")
            
            # ç¡®ä¿pad_token_idå·²è®¾ç½®
            if self.tokenizer.pad_token_id is None:
                self.tokenizer.pad_token_id = self.tokenizer.eos_token_id if self.tokenizer.eos_token_id else 0
            
            print(f"ğŸ“‹ Tokenizeré…ç½®: pad_token={self.tokenizer.pad_token}, pad_token_id={self.tokenizer.pad_token_id}")
            
            # åŠ è½½æ¨¡å‹
            self.model = AutoModelForSequenceClassification.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16,
                device_map="auto",
                trust_remote_code=True
            )
            
            # å¦‚æœæ·»åŠ äº†æ–°çš„tokenï¼Œéœ€è¦è°ƒæ•´æ¨¡å‹åµŒå…¥å±‚
            if len(self.tokenizer) != self.model.config.vocab_size:
                print("ğŸ”„ è°ƒæ•´æ¨¡å‹è¯æ±‡è¡¨å¤§å°...")
                self.model.resize_token_embeddings(len(self.tokenizer))
            
            print("âœ… Qwen3-Rerankeræ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ åŠ è½½Rerankeræ¨¡å‹å¤±è´¥: {e}")
            self.model = None
            self.tokenizer = None
            raise
    
    def rerank_single(self, query: str, document: str) -> float:
        """å•æ–‡æ¡£é‡æ’åº - é¿å…æ‰¹é‡å¤„ç†é—®é¢˜"""
        try:
            # æ„å»ºå•ä¸ªè¾“å…¥å¯¹
            pair = [query, document]
            
            # ç¼–ç å•ä¸ªè¾“å…¥
            inputs = self.tokenizer(
                pair,
                padding=True,  # å•ä¸ªæ ·æœ¬ä¹Ÿéœ€è¦paddingä»¥ç¡®ä¿ä¸€è‡´æ€§
                truncation=True,
                max_length=512,
                return_tensors="pt",
                return_token_type_ids=True
            ).to(self.model.device)
            
            # æ¨ç†
            with torch.no_grad():
                outputs = self.model(**inputs)
                score = torch.softmax(outputs.logits, dim=1)[0, 1].item()
            
            return score
            
        except Exception as e:
            print(f"âŒ å•æ–‡æ¡£é‡æ’åºå¤±è´¥: {e}")
            return 0.5  # é»˜è®¤åˆ†æ•°
    
    def rerank(self, query: str, documents: List[str]) -> List[Dict]:
        """å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº - ä½¿ç”¨é€æ–‡æ¡£å¤„ç†é¿å…æ‰¹é‡é—®é¢˜"""
        if not documents or self.model is None:
            return []
        
        try:
            # é€æ–‡æ¡£å¤„ç†ï¼Œé¿å…æ‰¹é‡paddingé—®é¢˜
            results = []
            for i, doc in enumerate(documents):
                score = self.rerank_single(query, doc)
                results.append({
                    'document': doc,
                    'score': score,
                    'rank': i
                })
            
            # æŒ‰åˆ†æ•°æ’åº
            results.sort(key=lambda x: x['score'], reverse=True)
            
            print(f"âœ… é‡æ’åºå®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªæ–‡æ¡£")
            return results
            
        except Exception as e:
            print(f"âŒ é‡æ’åºå¤±è´¥: {e}")
            # è¿”å›åŸå§‹é¡ºåº
            return [{'document': doc, 'score': 0.5, 'rank': i} for i, doc in enumerate(documents)]

class HybridRetriever:
    def __init__(self, config: Config):
        self.config = config
        self.reranker = None
        
        # åªæœ‰åœ¨æä¾›äº†Rerankeræ¨¡å‹è·¯å¾„æ—¶æ‰åˆå§‹åŒ–
        if config.RERANKER_MODEL_PATH and os.path.exists(config.RERANKER_MODEL_PATH):
            try:
                self.reranker = QwenReranker(config.RERANKER_MODEL_PATH)
                print("âœ… Rerankeråˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ Rerankeråˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–æ£€ç´¢: {e}")
                self.reranker = None
        else:
            print("âš ï¸ æœªé…ç½®Rerankeræ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨ç®€åŒ–æ£€ç´¢")
    
    def retrieve(self, query: str, vector_store, top_k: int = 10, rerank_k: int = 5) -> List[Dict]:
        """æ··åˆæ£€ç´¢ä¸é‡æ’åº"""
        try:
            if vector_store is None or vector_store.collection is None:
                print("âš ï¸ Milvusä¸å¯ç”¨ï¼Œè¿”å›ç©ºç»“æœ")
                return []
                
            # 1. å‘é‡æ£€ç´¢
            vector_results = vector_store.similarity_search(query, k=top_k)
            
            if not vector_results:
                return []
            
            # å¦‚æœæ²¡æœ‰rerankeræˆ–è€…rerankerå¤±è´¥ï¼Œç›´æ¥è¿”å›å‘é‡æ£€ç´¢ç»“æœ
            if self.reranker is None or self.reranker.model is None:
                print("âš ï¸ ä½¿ç”¨ç®€åŒ–æ£€ç´¢ï¼ˆæ— Rerankerï¼‰")
                return vector_results[:rerank_k]
            
            # 2. æå–æ–‡æ¡£å†…å®¹ç”¨äºé‡æ’åº
            documents = [result['content'] for result in vector_results]
            
            # 3. ä½¿ç”¨Qwen3-Rerankerè¿›è¡Œç²¾æ’
            print("ğŸ”„ ä½¿ç”¨Qwen3-Rerankerè¿›è¡Œé‡æ’åº...")
            reranked_results = self.reranker.rerank(query, documents)
            
            # 4. åˆå¹¶ç»“æœ
            final_results = []
            for rerank_item in reranked_results[:rerank_k]:
                original_index = rerank_item['rank']
                if original_index < len(vector_results):
                    final_result = vector_results[original_index].copy()
                    final_result['rerank_score'] = rerank_item['score']
                    final_result['final_score'] = rerank_item['score'] - final_result.get('distance', 0) * 0.1
                    final_results.append(final_result)
            
            # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
            final_results.sort(key=lambda x: x.get('final_score', 0), reverse=True)
            
            print(f"âœ… æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(final_results)} ä¸ªé‡æ’åºç»“æœ")
            return final_results
            
        except Exception as e:
            print(f"âŒ æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            # è¿”å›åŸå§‹å‘é‡æ£€ç´¢ç»“æœ
            return vector_results[:rerank_k] if 'vector_results' in locals() else []